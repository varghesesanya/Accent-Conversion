{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HLMIgaKc9rl2bWA3EEVvRn3NoHyAZneh",
      "authorship_tag": "ABX9TyNGHYScrzoVpbvtAFT9IAwP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varghesesanya/Accent-Conversion/blob/master/AITutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dKYhxS_Lupk",
        "outputId": "1f9611e1-e756-4fa0-e121-fdccd137958f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-mistralai langchain_community mistralai==0.4.2\n",
        "!pip install helper\n",
        "!pip install -qU langchain-mistralai\n",
        "!pip install python-dotenv\n",
        "!pip install PyPDF2\n",
        "!pip install langchain\n",
        "!pip install sentence-transformers\n",
        "!pip install -qU langchain-text-splitters\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq5ZZPn6KV4h",
        "outputId": "ab9f30a8-0b90-4f82-d824-f70e1e66d490"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-mistralai in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: mistralai==0.4.2 in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: httpx<1,>=0.25 in /usr/local/lib/python3.10/dist-packages (from mistralai==0.4.2) (0.27.2)\n",
            "Requirement already satisfied: orjson<3.11,>=3.9.10 in /usr/local/lib/python3.10/dist-packages (from mistralai==0.4.2) (3.10.7)\n",
            "Requirement already satisfied: pydantic<3,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from mistralai==0.4.2) (2.9.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.120)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: httpx-sse<1,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-mistralai) (0.4.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from langchain-mistralai) (0.19.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.5.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.25->mistralai==0.4.2) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.5.2->mistralai==0.4.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.5.2->mistralai==0.4.2) (2.23.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.24.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2024.6.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.66.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.25->mistralai==0.4.2) (1.2.2)\n",
            "Requirement already satisfied: helper in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from helper) (6.0.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.120)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ygV2mVkg_ijD"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "from langchain_mistralai import MistralAIEmbeddings\n",
        "from langchain_text_splitters import (\n",
        "    Language,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "import getpass\n",
        "import PyPDF2\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables from the .env file\n",
        "load_dotenv('/content/drive/MyDrive/Computer Vision/AI Tutor Bonus Project/.env')\n",
        "\n",
        "# Retrieve the API key\n",
        "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
        "\n",
        "# Check if the API key is loaded correctly\n",
        "if not mistral_api_key:\n",
        "    raise ValueError(\"Mistral API key not found. Please check your .env file.\")\n",
        "\n",
        "# Set headers for the request\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {mistral_api_key}\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "x_fnz8xgKNe-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "OBs0ra9kSYf0"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/drive/MyDrive/Computer Vision/AI Tutor Bonus Project/Computer_Vision_Richard_Szeliski-Chapter1.pdf\"\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "documents = [Document(page_content=pdf_text)]\n"
      ],
      "metadata": {
        "id": "p6zdB91ySbN-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split text into chunks\n",
        "\n",
        "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.MARKDOWN, chunk_size=60, chunk_overlap=0\n",
        ")\n",
        "\n",
        "markdown_text = \"\"\"\n",
        "# Title\n",
        "\n",
        "This is a sample markdown text that will be split into chunks.\n",
        "\"\"\"\n",
        "\n",
        "md_docs = md_splitter.create_documents([pdf_text])\n",
        "md_docs\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "split_texts = text_splitter.split_text(pdf_text)  # Split directly into chunks of text\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "# Create a vector store with a sample text\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vectorstore = InMemoryVectorStore.from_texts(\n",
        "    split_texts,\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "\n",
        "# Use the vectorstore as a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Retrieve the most similar text\n",
        "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
        "\n",
        "# Show the retrieved document's content\n",
        "if retrieved_documents:\n",
        "    print(retrieved_documents[0].page_content)\n",
        "else:\n",
        "    print(\"No relevant documents found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp57049mKQ3y",
        "outputId": "a5a2954d-11d9-4002-9a0f-0f19e32818f1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-2ec0e7f36f8e>:21: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings()\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ure1.7d), along with the related 21/2-D sketch ideas of Marr (1982 ). This approach is again\n",
            "seeing a bit of a revival in the work of Tappen, Freeman, and Adelson (2005 ).\n",
            "More quantitative approaches to computer vision were also developed at the time, in-\n",
            "cluding the ﬁrst of many feature-based stereo correspondence algorithms (Figure 1.7e) (Dev\n",
            "1974 ;Marr and Poggio 1976 ;Moravec 1977 ;Marr and Poggio 1979 ;Mayhew and Frisby\n",
            "1981 ;Baker 1982 ;Barnard and Fischler 1982 ;Ohta and Kanade 1985 ;Grimson 1985 ;Pol-\n",
            "lard, Mayhew, and Frisby 1985 ;Prazdny 1985 ) and intensity-based optical ﬂow algorithms\n",
            "7In robotics and computer animation, these linked-part graphs are often called kinematic chains .12 1 Introduction\n",
            "(Figure 1.7f) (Horn and Schunck 1981 ;Huang 1981 ;Lucas and Kanade 1981 ;Nagel 1986 ).\n",
            "The early work in simultaneously recovering 3D structure and camera motion (see Chapter 7)\n",
            "also began around this time ( Ullman 1979 ;Longuet-Higgins 1981 ).\n",
            "A lot of the philosophy of how vision was believed to work at the time is summarized\n",
            "in David Marr’s ( 1982 ) book.8In particular, Marr introduced his notion of the three levels\n",
            "of description of a (visual) information processing system. These three levels, very loosely\n",
            "paraphrased according to my own interpretation, are:\n",
            "•Computational theory: What is the goal of the computation (task) and what are the\n",
            "constraints that are known or can be brought to bear on the problem?\n",
            "•Representations and algorithms: How are the input, output, and intermediate infor-\n",
            "mation represented and which algorithms are used to calculate the desired result?\n",
            "•Hardware implementation: How are the representations and algorithms mapped onto\n",
            "actual hardware, e.g., a biological vision system or a specialized piece of silicon? Con-\n",
            "versely, how can hardware constraints be used to guide the choice of representation\n",
            "and algorithm? With the increasing use of graphics chips (GPUs) and many-core ar-\n",
            "chitectures for computer vision (see Section C.2), this question is again becoming quite\n",
            "relevant.\n",
            "As I mentioned earlier in this introduction, it is my conviction that a careful analysis of the\n",
            "problem speciﬁcation and known constraints from image formation and priors (the scientiﬁc\n",
            "and statistical approaches) must be married with efﬁcient and robust algorithms (the engineer-\n",
            "ing approach) to design successful vision algorithms. Thus, it seems that Marr’s philosophy\n",
            "is as good a guide to framing and solving problems in our ﬁeld today as it was 25 years ago.\n",
            "1980s. In the 1980s, a lot of attention was focused on more sophisticated mathematical\n",
            "techniques for performing quantitative image and scene analysis.\n",
            "Image pyramids (see Section 3.5) started being widely used to perform tasks such as im-\n",
            "age blending (Figure 1.8a) and coarse-to-ﬁne correspondence search ( Rosenfeld 1980 ;Burt\n",
            "and Adelson 1983a ,b;Rosenfeld 1984 ;Quam 1984 ;Anandan 1989 ). Continuous versions\n",
            "of pyramids using the concept of scale-space processing were also developed ( Witkin 1983 ;\n",
            "Witkin, Terzopoulos, and Kass 1986 ;Lindeberg 1990 ). In the late 1980s, wavelets (see Sec-\n",
            "tion 3.5.4 ) started displacing or augmenting regular image pyramids in some applications\n",
            "(Adelson, Simoncelli, and Hingorani 1987 ;Mallat 1989 ;Simoncelli and Adelson 1990a ,b;\n",
            "Simoncelli, Freeman, Adelson et al. 1992 ).\n",
            "The use of stereo as a quantitative shape cue was extended by a wide variety of shape-\n",
            "from-X techniques, including shape from shading (Figure 1.8b) (see Section 12.1.1 andHorn\n",
            "1975 ;Pentland 1984 ;Blake, Zimmerman, and Knowles 1985 ;Horn and Brooks 1986 ,1989 ),\n",
            "photometric stereo (see Section 12.1.1 andWoodham 1981 ), shape from texture (see Sec-\n",
            "tion 12.1.2 andWitkin 1981 ;Pentland 1984 ;Malik and Rosenholtz 1997 ), and shape from\n",
            "focus (see Section 12.1.3 andNayar, Watanabe, and Noguchi 1995 ).Horn (1986 ) has a nice\n",
            "discussion of most of these techniques.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Assuming vectorstore is already created and split_texts is the list of text chunks\n",
        "# Use the vectorstore as a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Define the question you want to ask\n",
        "query = \"What are Vanishing Points\"\n",
        "\n",
        "# Retrieve the most similar text chunks from the vectorstore\n",
        "retrieved_documents = retriever.invoke(query)\n",
        "\n",
        "# Show the retrieved document's content\n",
        "if retrieved_documents:\n",
        "    print(retrieved_documents[0].page_content)\n",
        "else:\n",
        "    print(\"No relevant documents found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtrR8x7nPpHb",
        "outputId": "7c9c8ad4-d3de-4e43-ac81-9789883f4e39"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ing (see Section 14.1.1 );\n",
            "•Visual authentication: automatically logging family members onto your home com-\n",
            "puter as they sit down in front of the webcam (see Section 14.2).\n",
            "The great thing about these applications is that they are already familiar to most students;\n",
            "they are, at least, technologies that students can immediately appreciate and use with their\n",
            "own personal media. Since computer vision is a challenging topic, given the wide range\n",
            "of mathematics being covered4and the intrinsically difﬁcult nature of the problems being\n",
            "solved, having fun and relevant problems to work on can be highly motivating and inspiring.\n",
            "The other major reason why this book has a strong focus on applications is that they can\n",
            "be used to formulate andconstrain the potentially open-ended problems endemic in vision.\n",
            "For example, if someone comes to me and asks for a good edge detector, my ﬁrst question is\n",
            "usually to ask why? What kind of problem are they trying to solve and why do they believe\n",
            "that edge detection is an important component? If they are trying to locate faces, I usually\n",
            "point out that most successful face detectors use a combination of skin color detection (Exer-\n",
            "cise2.8) and simple blob features Section 14.1.1 ; they do not rely on edge detection. If they\n",
            "are trying to match door and window edges in a building for the purpose of 3D reconstruction,\n",
            "I tell them that edges are a ﬁne idea but it is better to tune the edge detector for long edges\n",
            "(see Sections 3.2.3 and4.2) and link them together into straight lines with common vanishing\n",
            "points before matching (see Section 4.3).\n",
            "Thus, it is better to think back from the problem at hand to suitable techniques, rather\n",
            "than to grab the ﬁrst technique that you may have heard of. This kind of working back from\n",
            "3For a fun student project on this topic, see the “PhotoBook” project at http://www.cc.gatech.edu/dvfx/videos/\n",
            "dvfx2005.html .\n",
            "4These techniques include physics, Euclidean and projective geometry, statistics, and optimization. They make\n",
            "computer vision a fascinating ﬁeld to study and a great way to learn techniques widely applicable in other ﬁelds.8 1 Introduction\n",
            "(a)\n",
            "(b)\n",
            "(c)\n",
            "(d)\n",
            "Figure 1.5 Some consumer applications of computer vision: (a) image stitching: merging different views\n",
            "(Szeliski and Shum 1997 )c/circlecopyrt1997 ACM; (b) exposure bracketing: merging different exposures; (c) morphing:\n",
            "blending between two photographs ( Gomes, Darsa, Costa et al. 1999 )c/circlecopyrt1999 Morgan Kaufmann; (d) turning a\n",
            "collection of photographs into a 3D model ( Sinha, Steedly, Szeliski et al. 2008 )c/circlecopyrt2008 ACM.1.1 What is computer vision? 9\n",
            "problems to solutions is typical of an engineering approach to the study of vision and reﬂects\n",
            "my own background in the ﬁeld. First, I come up with a detailed problem deﬁnition and\n",
            "decide on the constraints and speciﬁcations for the problem. Then, I try to ﬁnd out which\n",
            "techniques are known to work, implement a few of these, evaluate their performance, and\n",
            "ﬁnally make a selection. In order for this process to work, it is important to have realistic test\n",
            "data , both synthetic, which can be used to verify correctness and analyze noise sensitivity,\n",
            "and real-world data typical of the way the system will ﬁnally be used.\n",
            "However, this book is not just an engineering text (a source of recipes). It also takes a\n",
            "scientiﬁc approach to basic vision problems. Here, I try to come up with the best possible\n",
            "models of the physics of the system at hand: how the scene is created, how light interacts\n",
            "with the scene and atmospheric effects, and how the sensors work, including sources of noise\n",
            "and uncertainty. The task is then to try to invert the acquisition process to come up with the\n",
            "best possible description of the scene.\n",
            "The book often uses a statistical approach to formulating and solving computer vision\n",
            "problems. Where appropriate, probability distributions are used to model the scene and the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmkJ5m_cbKxI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}